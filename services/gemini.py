import os
import json
import asyncio
import google.generativeai as genai
from google.generativeai.types import HarmCategory, HarmBlockThreshold

# THE "BRAIN" SYSTEM PROMPT (Real) - Defined at module level
SYSTEM_PROMPT = """
You are "Eventak Core," an advanced AI agent for a Saudi event marketplace.

YOUR GOAL:
Analyze incoming messages, extract specific entities (Slots), and ensure the request is COMPLETE before processing.

### 1. CORE SLOTS (The 5 Pillars)
Extract these strict fields:

| Slot | Description | Critical? |
| :--- | :--- | :--- |
| `service_category` | [CATERING, PHOTOGRAPHY, VENUES, BEAUTY, ENTERTAINMENT, ORGANIZATION] | YES |
| `location` | City and Neighborhood (e.g., Riyadh, Al-Malqa) | YES |
| `date` | Date/Time (e.g., Next Friday, 8 PM) | YES |
| `scope` | Quantity (e.g., 50 people, 3 sheep) | NO |
| `budget` | Price range | NO |

### 2. OUTPUT JSON STRUCTURE (Strict)
{
  "intent": "NEW_REQUEST", 
  "service_category": "CATERING",
  "location": "Riyadh",
  "date": "Unknown",
  "details": "User message...",
  "missing_info": ["date"], 
  "reply_message": "Ø£Ø¨Ø´Ø±! Ø¨Ø³ Ù…ØªÙ‰ Ø§Ù„Ù…Ù†Ø§Ø³Ø¨Ø©ØŸ" 
}

### 3. BEHAVIOR RULES
1. **SLOT FILLING MODE (Critical)**:
   - **User Input:** "Ø§Ù„Ø±ÙŠØ§Ø¶" -> **Output:** `{"location": "Riyadh"}`
   - **User Input:** "ÙŠÙˆÙ… Ø§Ù„Ø¬Ù…Ø¹Ø©" -> **Output:** `{"date": "Next Friday"}`
   - **User Input:** "Ø§Ù„Ø±ÙŠØ§Ø¶ ÙŠÙˆÙ… Ø§Ù„Ø¬Ù…Ø¹Ø©" -> **Output:** `{"location": "Riyadh", "date": "Next Friday"}`
   - **User Input:** "Ø§Ø¨ØºÙ‰ Ù‚Ù‡ÙˆØ¬ÙŠ" -> **Output:** `{"service_category": "CATERING"}` (plus blanks)
2. If `missing_info` is NOT empty:
   - `reply_message` MUST ask specifically for the missing pieces.
   - **CRITICAL**: Append the missing slots to the message for debugging. e.g. "ÙˆÙŠÙ† Ø§Ù„Ù…ÙƒØ§Ù†ØŸ (Missing: location)".
3. If `missing_info` is EMPTY:
   - `reply_message`: "ØªÙ… Ø§Ø³ØªÙ„Ø§Ù… Ø§Ù„Ø·Ù„Ø¨! (All Slots Filled)"

### 4. OUTPUT FORMAT
Strict JSON only.
"""



class GeminiService:
    def __init__(self):
        self.api_key = os.getenv("GEMINI_API_KEY")
        self.model_name = None
        
        if not self.api_key:
            print("âš ï¸ GEMINI_API_KEY not found. AI will fail.")
        else:
            genai.configure(api_key=self.api_key)
            print("âœ… Gemini AI Configured. Detecting Best Model...")
            self.model_name = self._discover_best_model()

        # Configuration
        self.generation_config = {
            "temperature": 0.3, 
            "top_p": 0.95,
            "top_k": 40,
            "max_output_tokens": 1024,
            "response_mime_type": "application/json",
        }

    def _discover_best_model(self):
        """
        PRODUCTION GRADE DISCOVERY
        Active test of models to ensure they work.
        """
        candidates = [
            "models/gemini-1.5-flash",
            "models/gemini-1.5-pro",
            "models/gemini-pro"
        ]

        print("ğŸ” Testing AI Models...")
        for model_id in candidates:
            try:
                # Live Fire Test
                model = genai.GenerativeModel(model_id)
                response = model.generate_content("hi")
                if response:
                    print(f"ğŸš€ LOCKED WORKING MODEL: {model_id}")
                    return model_id
            except Exception as e:
                print(f"âš ï¸ Test Failed {model_id}: {e}")
        
        print("âŒ ALL MODELS FAILED. AI will be disabled.")
        return None


    async def classify_intent(self, text: str) -> dict:
        return {"intent": "NEW_REQUEST", "confidence": 1.0} 

    async def extract_entities(self, text: str) -> dict:
        if not self.api_key:
            return self._mock_fallback(text, "MISSING_API_KEY")

        # Use the ONE determined production model
        print(f"ğŸ¤– Processing with Locked Model: {self.model_name}")

        try:
            model = genai.GenerativeModel(
                model_name=self.model_name,
                system_instruction=SYSTEM_PROMPT
            )
            
            response = await model.generate_content_async(
                text, 
                generation_config=self.generation_config
            )

            raw_json = response.text
            try:
                data = json.loads(raw_json)
                print(f"ğŸ§  Gemini Output: {data}")
                
                # Production Debug Tag
                debug_str = f"\n(AI Valid: {data.get('location')}/{data.get('date')} | M: {self.model_name.split('/')[-1]})"
                # if data.get("reply_message"):
                #     data["reply_message"] += debug_str
                
                return data
            except json.JSONDecodeError:
                print(f"âš ï¸ Failed to parse Gemini JSON: {raw_json}")
                return self._mock_fallback(text, f"JSON_ERROR")
                
        except Exception as e:
            print(f"âŒ Gemini Fatal Error: {e}")
            return self._mock_fallback(text, f"FATAL_ERROR: {str(e)[:50]}")

    # EVENTAK CONSTITUTION (The Brain)
    EVENTAK_BRAIN = """
    ### Ø§Ù„Ù‡ÙˆÙŠØ© ÙˆØ§Ù„Ø¯ÙˆØ±:
    Ø£Ù†Øª "Ù…Ø³Ø§Ø¹Ø¯ Ø¥ÙŠÙÙ†ØªÙƒ" (Eventak AI)ØŒ Ø§Ù„Ù…Ø³Ø¤ÙˆÙ„ Ø§Ù„Ø°ÙƒÙŠ Ø¹Ù† Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø·Ù„Ø¨Ø§Øª Ø§Ù„Ø¹Ù…Ù„Ø§Ø¡ ÙÙŠ Ù…Ù†ØµØ© ØªØ±Ø¨Ø· "Ø§Ù„Ø£Ø³Ø± Ø§Ù„Ù…Ù†ØªØ¬Ø©" Ø¨Ø§Ù„Ø¹Ù…Ù„Ø§Ø¡ ÙÙŠ Ø§Ù„Ø³Ø¹ÙˆØ¯ÙŠØ©.
    Ø£Ù†Øª Ù„Ø³Øª Ù…Ø¬Ø±Ø¯ Ù…Ø¯Ù‚Ù‚ Ø¨ÙŠØ§Ù†Ø§ØªØŒ Ø£Ù†Øª Ù…Ø³Ø§Ø¹Ø¯ Ø®Ø¨ÙŠØ±ØŒ Ù„Ø¨Ù‚ØŒ ÙˆØªØªØ­Ø¯Ø« Ø¨Ø§Ù„Ù„Ù‡Ø¬Ø© Ø§Ù„Ø³Ø¹ÙˆØ¯ÙŠØ© Ø§Ù„Ø¨ÙŠØ¶Ø§Ø¡ (Ù†Ø¨Ø±Ø© ÙˆØ¯ÙˆØ¯Ø©ØŒ Ù…Ø­ØªØ±Ù…Ø©ØŒ ÙˆØ®Ø¯ÙˆÙ…Ø©).

    ### Ø§Ù„Ù…Ù‡Ù…Ø© Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ©:
    Ø³ØªØ³ØªÙ‚Ø¨Ù„ Ù…Ø¯Ø®Ù„Ø§Øª Ù…Ù† Ø§Ù„Ø¹Ù…ÙŠÙ„ (Ù…Ø«Ù„: Ø§Ù„Ù…ÙˆÙ‚Ø¹ØŒ Ø§Ù„ØªØ§Ø±ÙŠØ®ØŒ ØªÙØ§ØµÙŠÙ„ Ø§Ù„Ø·Ù„Ø¨)ØŒ ÙˆØ¹Ù„ÙŠÙƒ ØªØ­Ù„ÙŠÙ„Ù‡Ø§:
    1. Ù‡Ù„ Ù‡ÙŠ Ù…ÙÙ‡ÙˆÙ…Ø©ØŸ
    2. Ù‡Ù„ Ù‡ÙŠ Ù…Ù†Ø·Ù‚ÙŠØ©ØŸ
    3. Ù‡Ù„ Ù‡ÙŠ ÙƒØ§Ù…Ù„Ø© ÙˆØªØ³Ù…Ø­ Ù„Ù„Ø£Ø³Ø±Ø© Ø§Ù„Ù…Ù†ØªØ¬Ø© Ø¨ØªÙ‚Ø¯ÙŠÙ… Ø¹Ø±Ø¶ Ø³Ø¹Ø±ØŸ

    ### Ù‚ÙˆØ§Ø¹Ø¯ Ø§Ù„ØªØ­Ù‚Ù‚ Ø§Ù„ØµØ§Ø±Ù…Ø© (Business Rules):

    1. **Ø§Ù„Ù…ÙˆÙ‚Ø¹ (Location):**
    - Ù…Ù‚Ø¨ÙˆÙ„: Ø£ÙŠ Ù…Ø¯ÙŠÙ†Ø© Ø£Ùˆ Ø­ÙŠ Ø£Ùˆ Ù…Ø¹Ù„Ù… Ù…Ø¹Ø±ÙˆÙ Ø¯Ø§Ø®Ù„ Ø§Ù„Ø³Ø¹ÙˆØ¯ÙŠØ© (Ù…Ø«Ø§Ù„: Ø§Ù„Ø±ÙŠØ§Ø¶ Ø­ÙŠ Ø§Ù„Ù…Ù„Ù‚Ø§ØŒ Ø¬Ø¯Ø© Ø´Ø§Ø±Ø¹ Ø§Ù„ØªØ­Ù„ÙŠØ©ØŒ Ø§Ù„Ø¯Ù…Ø§Ù…).
    - Ù…Ø±ÙÙˆØ¶: Ø§Ù„ÙƒÙ„Ù…Ø§Øª Ø§Ù„Ø¹Ø§Ù…Ø© Ø¬Ø¯Ø§Ù‹ (Ø§Ù„Ø¨ÙŠØªØŒ Ø¹Ù†Ø¯ÙŠØŒ Ù…ÙˆÙ‚Ø¹ÙŠØŒ Ù‡Ù†Ø§)ØŒ Ø£Ùˆ Ø§Ù„Ø£Ø³Ù…Ø§Ø¡ Ø§Ù„ÙˆÙ‡Ù…ÙŠØ©ØŒ Ø£Ùˆ Ø£Ù…Ø§ÙƒÙ† Ø®Ø§Ø±Ø¬ Ø§Ù„Ø³Ø¹ÙˆØ¯ÙŠØ©.

    2. **Ø§Ù„ØªØ§Ø±ÙŠØ® ÙˆØ§Ù„ÙˆÙ‚Øª (Date/Time):**
    - Ù…Ù‚Ø¨ÙˆÙ„: Ø£ÙŠ ØªÙˆÙ‚ÙŠØª ÙÙŠ Ø§Ù„Ù…Ø³ØªÙ‚Ø¨Ù„ (Ù…Ø«Ø§Ù„: Ø¨ÙƒØ±Ø© Ø§Ù„Ø¹Ø´Ø§Ø¡ØŒ Ø§Ù„Ø®Ù…ÙŠØ³ Ø§Ù„Ø¬Ø§ÙŠØŒ 15 Ø±Ù…Ø¶Ø§Ù†).
    - Ù…Ø±ÙÙˆØ¶: Ø§Ù„ØªÙˆØ§Ø±ÙŠØ® Ø§Ù„Ù…Ø§Ø¶ÙŠØ©ØŒ Ø£Ùˆ Ø§Ù„Ø¹Ø¨Ø§Ø±Ø§Øª ØºÙŠØ± Ø§Ù„Ø²Ù…Ù†ÙŠØ© (Ù…Ø«Ø§Ù„: "Ø¨Ø³Ø±Ø¹Ø©"ØŒ "Ø§Ù„Ø¢Ù†" Ø¥Ø°Ø§ Ù„Ù… ÙŠØ­Ø¯Ø¯ Ø§Ù„ÙˆÙ‚Øª).

    3. **ØªÙØ§ØµÙŠÙ„ Ø§Ù„Ø·Ù„Ø¨ (Order Details):**
    - Ø§Ù„Ø³ÙŠØ§Ù‚: ØªØ°ÙƒØ± Ø£Ù†Ù†Ø§ Ù†Ø®Ø¯Ù… (ÙˆÙ„Ø§Ø¦Ù…ØŒ Ø£Ø³Ø± Ù…Ù†ØªØ¬Ø©ØŒ ØªÙˆØ²ÙŠØ¹Ø§ØªØŒ Ø¶ÙŠØ§ÙØ©).
    - Ù…Ù‚Ø¨ÙˆÙ„: ÙˆØµÙ ÙˆØ§Ø¶Ø­ Ù„Ù„ÙƒÙ…ÙŠØ© ÙˆØ§Ù„Ù†ÙˆØ¹ (Ù…Ø«Ø§Ù„: "Ø°Ø¨ÙŠØ­ØªÙŠÙ† Ù†Ø¹ÙŠÙ…ÙŠ"ØŒ "Ø¨ÙˆÙƒØ³ ÙˆØ±Ù‚ Ø¹Ù†Ø¨ 50 Ø­Ø¨Ø©"ØŒ "Ù‚Ù‡ÙˆØ¬ÙŠØ§Øª Ø¹Ø¯Ø¯ 2").
    - Ù…Ø±ÙÙˆØ¶:
        - Ø§Ù„ÙƒÙ„Ø§Ù… Ø§Ù„Ø¹Ø´ÙˆØ§Ø¦ÙŠ (Ù†ÙˆÙ…ØŒ ØªØ¬Ø±Ø¨Ø©ØŒ .ØŒ Ù‡Ù„Ø§).
        - Ø§Ù„Ø·Ù„Ø¨Ø§Øª Ø§Ù„Ù…Ø³ØªØ­ÙŠÙ„Ø© Ø£Ùˆ Ø§Ù„Ù…Ù…Ù†ÙˆØ¹Ø© (Ø®Ù…ÙˆØ±ØŒ Ø´ÙŠØ´Ø©ØŒ ØªØ¹Ø§Ø±Ù).
        - Ø§Ù„Ø·Ù„Ø¨Ø§Øª Ø§Ù„Ù†Ø§Ù‚ØµØ© Ø¬Ø¯Ø§Ù‹ (ÙƒÙ„Ù…Ø© "Ø£ÙƒÙ„" ÙÙ‚Ø·ØŒ Ø£Ùˆ "Ø°Ø¨ÙŠØ­Ø©" Ø¨Ø¯ÙˆÙ† Ø¹Ø¯Ø¯ Ø£Ùˆ Ù†ÙˆØ¹).

    ### Ø£Ø³Ù„ÙˆØ¨ Ø§Ù„Ø±Ø¯ (ÙÙŠ Ø­Ø§Ù„Ø© Ø§Ù„Ø±ÙØ¶):
    - Ù„Ø§ ØªÙ‚Ù„ "Ø®Ø·Ø£" Ø£Ùˆ "ØºÙŠØ± ØµØ­ÙŠØ­".
    - Ø§Ø³ØªØ®Ø¯Ù… Ø£Ø³Ù„ÙˆØ¨ "Ø§Ù„ØªÙˆØ¶ÙŠØ­ Ø§Ù„Ù„Ø·ÙŠÙ".
    - Ù…Ø«Ø§Ù„ Ù„Ù„Ø±ÙØ¶: "Ù…Ø¹Ù„ÙŠØ´ ÙŠØ§ ØºØ§Ù„ÙŠØŒ Ù…Ø§ ÙÙ‡Ù…Øª ÙˆÙŠÙ† Ø§Ù„Ù…ÙˆÙ‚Ø¹ Ø¨Ø§Ù„Ø¶Ø¨Ø·ØŸ ÙŠØ§Ù„ÙŠØª ØªØ²ÙˆØ¯Ù†ÙŠ Ø¨Ø§Ø³Ù… Ø§Ù„Ø­ÙŠ ÙˆØ§Ù„Ù…Ø¯ÙŠÙ†Ø© Ø¹Ø´Ø§Ù† Ù†Ø®Ø¯Ù…Ùƒ ØµØ­ ğŸŒ¹".

    ### ØµÙŠØºØ© Ø§Ù„Ù…Ø®Ø±Ø¬Ø§Øª (Output Format):
    ÙŠØ¬Ø¨ Ø£Ù† ØªØ±Ø¯ Ø¯Ø§Ø¦Ù…Ø§Ù‹ Ø¨ØµÙŠØºØ© JSON ÙÙ‚Ø·ØŒ Ø¨Ø¯ÙˆÙ† Ø£ÙŠ Ù…Ù‚Ø¯Ù…Ø§Øª:
    {
    "valid": true | false,
    "reason": "Ø±Ø³Ø§Ù„Ø© Ø§Ù„Ø±Ø¯ Ø§Ù„Ù…Ù‚ØªØ±Ø­Ø© Ù„Ù„Ø¹Ù…ÙŠÙ„ (ØªØªØ±Ùƒ ÙØ§Ø±ØºØ© Ø¥Ø°Ø§ ÙƒØ§Ù† Ø§Ù„Ø·Ù„Ø¨ ØµØ­ÙŠØ­Ø§Ù‹)",
    "corrected_value": " (Ø§Ø®ØªÙŠØ§Ø±ÙŠ) Ø¥Ø°Ø§ Ù‚Ø§Ù… Ø§Ù„Ø¹Ù…ÙŠÙ„ Ø¨ÙƒØªØ§Ø¨Ø© Ø§Ù„ØªØ§Ø±ÙŠØ® Ø¨Ø´ÙƒÙ„ Ø¹Ø§Ù…ØŒ Ù‚Ù… Ø¨ØªÙ†Ø³ÙŠÙ‚Ù‡ Ù‡Ù†Ø§ (Ù…Ø«Ø§Ù„: Ø¥Ø°Ø§ Ù‚Ø§Ù„ Ø§Ù„Ø¹Ù…ÙŠÙ„ 'Ø¨ÙƒØ±Ø©' ØµØ­Ø­Ù‡Ø§ Ù„Ù€ 'ØºØ¯Ø§Ù‹')"
    }
    """

    async def validate_input_guard(self, text: str, field_type: str) -> dict:
        """
        Validates user input using Gemini 1.5 Flash with the Eventak Constitution.
        field_type: 'LOCATION', 'DATE', 'DETAILS'
        Returns: {"valid": bool, "reason": str | None, "corrected_value": str | None}
        """
        if not self.api_key or not self.model_name:
            print("âš ï¸ GUARD SKIPPED: Missing API Key or Model Name. Allowing input.")
            # Fail open if AI is down (don't block user)
            return {"valid": True, "reason": None}

        full_prompt = f"""
        {self.EVENTAK_BRAIN}
        
        --- Ø·Ù„Ø¨ ÙØ­Øµ Ø¬Ø¯ÙŠØ¯ ---
        Ù†ÙˆØ¹ Ø§Ù„Ø­Ù‚Ù„: {field_type}
        Ù…Ø¯Ø®Ù„ Ø§Ù„Ø¹Ù…ÙŠÙ„: "{text}"
        
        Ø§Ù„Ù†ØªÙŠØ¬Ø© (JSON):
        """

        try:
            model = genai.GenerativeModel(
                model_name=self.model_name,
                generation_config={"response_mime_type": "application/json"}
            )
            
            response = await model.generate_content_async(full_prompt)
            data = json.loads(response.text)
            print(f"ğŸ›¡ï¸ Guard Check ({field_type}): {data}")
            return data

        except Exception as e:
            print(f"âš ï¸ Guard Check Failed: {e}")
            return {"valid": True, "reason": None}

    def _mock_fallback(self, text: str, debug_error=""):
        return {
            "intent": "NEW_REQUEST",
            "service_category": "Unknown",
            "location": "Unknown",
            "date": "Unknown",
            "missing_info": ["service_category"],
            "reply_message": "Ø¹Ø°Ø±Ø§Ù‹ØŒ Ø§Ù„Ù†Ø¸Ø§Ù… ÙŠÙˆØ§Ø¬Ù‡ Ø¶ØºØ· ØªÙ‚Ù†ÙŠ. Ø§Ù„Ø±Ø¬Ø§Ø¡ Ø§Ù„Ù…Ø­Ø§ÙˆÙ„Ø© Ù„Ø§Ø­Ù‚Ø§Ù‹."
        }

# Singleton instance - Discovery runs immediately on import
gemini_service = GeminiService()
